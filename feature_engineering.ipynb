{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "982e0ee7-680f-4e65-a2f0-0211bf3ce468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before cleaning:\n",
      "\n",
      "Employee_ID                 0\n",
      "Name                        0\n",
      "Age                       286\n",
      "Gender                     34\n",
      "Department                  0\n",
      "Experience_Years          273\n",
      "Education_Level             0\n",
      "Salary_USD                 58\n",
      "Bonus_%                     0\n",
      "Job_Role                    0\n",
      "Joining_Date                0\n",
      "City                        0\n",
      "State                       0\n",
      "Country                     0\n",
      "Performance_Rating        207\n",
      "Remote_Work               374\n",
      "Overtime_Hours_Monthly    365\n",
      "Projects_Handled            0\n",
      "Attrition                   0\n",
      "dtype: int64\n",
      "\n",
      "Missing values after cleaning:\n",
      "\n",
      "Employee_ID               0\n",
      "Name                      0\n",
      "Age                       0\n",
      "Gender                    0\n",
      "Department                0\n",
      "Experience_Years          0\n",
      "Education_Level           0\n",
      "Salary_USD                0\n",
      "Bonus_%                   0\n",
      "Job_Role                  0\n",
      "Joining_Date              0\n",
      "City                      0\n",
      "State                     0\n",
      "Country                   0\n",
      "Performance_Rating        0\n",
      "Remote_Work               0\n",
      "Overtime_Hours_Monthly    0\n",
      "Projects_Handled          0\n",
      "Attrition                 0\n",
      "dtype: int64\n",
      "\n",
      "✅ Noisy values cleaned.\n",
      "\n",
      "        Employee_ID    Name          Age Gender  Department  Experience_Years  \\\n",
      "count        1102.0  1102.0  1102.000000   1102      1102.0       1102.000000   \n",
      "unique        715.0   195.0          NaN      5         8.0               NaN   \n",
      "top            58.0    58.0          NaN   Male        58.0               NaN   \n",
      "freq          354.0   354.0          NaN    370       354.0               NaN   \n",
      "mean            NaN     NaN    43.718693    NaN         NaN         29.572518   \n",
      "min             NaN     NaN    18.000000    NaN         NaN          0.047033   \n",
      "25%             NaN     NaN    33.000000    NaN         NaN          9.600000   \n",
      "50%             NaN     NaN    41.000000    NaN         NaN         20.873207   \n",
      "75%             NaN     NaN    58.000000    NaN         NaN         58.000000   \n",
      "max             NaN     NaN    65.000000    NaN         NaN         58.000000   \n",
      "std             NaN     NaN    11.927072    NaN         NaN         21.683330   \n",
      "\n",
      "        Education_Level    Salary_USD      Bonus_%  Job_Role  \\\n",
      "count            1102.0   1102.000000  1102.000000    1102.0   \n",
      "unique              5.0           NaN          NaN       6.0   \n",
      "top                58.0           NaN          NaN      58.0   \n",
      "freq              354.0           NaN          NaN     354.0   \n",
      "mean                NaN   3272.203778    25.437246       NaN   \n",
      "min                 NaN     56.710000     0.000000       NaN   \n",
      "25%                 NaN     58.000000     8.392500       NaN   \n",
      "50%                 NaN   3506.610000    13.145000       NaN   \n",
      "75%                 NaN   5511.737500    58.000000       NaN   \n",
      "max                 NaN  11386.220000    58.000000       NaN   \n",
      "std                 NaN   2844.287005    22.773165       NaN   \n",
      "\n",
      "                         Joining_Date    City   State  Country  \\\n",
      "count                            1102  1102.0  1102.0   1102.0   \n",
      "unique                            NaN     8.0     8.0      5.0   \n",
      "top                               NaN    58.0    58.0     58.0   \n",
      "freq                              NaN   354.0   354.0    354.0   \n",
      "mean    2013-07-31 23:03:48.675136256     NaN     NaN      NaN   \n",
      "min               2005-01-11 00:00:00     NaN     NaN      NaN   \n",
      "25%               2011-07-06 00:00:00     NaN     NaN      NaN   \n",
      "50%               2011-07-06 00:00:00     NaN     NaN      NaN   \n",
      "75%               2017-02-18 06:00:00     NaN     NaN      NaN   \n",
      "max               2023-12-28 00:00:00     NaN     NaN      NaN   \n",
      "std                               NaN     NaN     NaN      NaN   \n",
      "\n",
      "        Performance_Rating Remote_Work  Overtime_Hours_Monthly  \\\n",
      "count          1102.000000        1102             1102.000000   \n",
      "unique                 NaN           3                     NaN   \n",
      "top                    NaN          No                     NaN   \n",
      "freq                   NaN         510                     NaN   \n",
      "mean             20.813067         NaN               47.612523   \n",
      "min               1.000000         NaN                0.000000   \n",
      "25%               3.000000         NaN               40.000000   \n",
      "50%               4.000000         NaN               58.000000   \n",
      "75%              58.000000         NaN               58.000000   \n",
      "max              58.000000         NaN               60.000000   \n",
      "std              25.617452         NaN               17.571795   \n",
      "\n",
      "        Projects_Handled Attrition  \n",
      "count        1102.000000      1102  \n",
      "unique               NaN         3  \n",
      "top                  NaN       Yes  \n",
      "freq                 NaN       386  \n",
      "mean           29.343013       NaN  \n",
      "min             1.000000       NaN  \n",
      "25%            12.000000       NaN  \n",
      "50%            23.000000       NaN  \n",
      "75%            58.000000       NaN  \n",
      "max            58.000000       NaN  \n",
      "std            21.005089       NaN  \n",
      "\n",
      "Duplicate rows before removal: 371\n",
      "Duplicate rows after removal: 0\n",
      "Dataset shape: (731, 19)\n",
      "\n",
      "--- Age ---\n",
      "Lower Bound: 21.0\n",
      "Upper Bound: 53.0\n",
      "Outliers before: 65\n",
      "Outliers after: 0\n",
      "\n",
      "--- Experience_Years ---\n",
      "Lower Bound: -9.311648261383274\n",
      "Upper Bound: 41.11941376897212\n",
      "Outliers before: 37\n",
      "Outliers after: 0\n",
      "\n",
      "--- Salary_USD ---\n",
      "Lower Bound: -933.017656250001\n",
      "Upper Bound: 10596.242593750001\n",
      "Outliers before: 4\n",
      "Outliers after: 0\n",
      "\n",
      "--- Bonus_% ---\n",
      "Lower Bound: -3.9125000000000005\n",
      "Upper Bound: 23.747500000000002\n",
      "Outliers before: 2\n",
      "Outliers after: 0\n",
      "\n",
      "--- Performance_Rating ---\n",
      "Lower Bound: -1.0\n",
      "Upper Bound: 7.0\n",
      "Outliers before: 1\n",
      "Outliers after: 0\n",
      "\n",
      "--- Overtime_Hours_Monthly ---\n",
      "Lower Bound: -20.75\n",
      "Upper Bound: 105.25\n",
      "Outliers before: 0\n",
      "Outliers after: 0\n",
      "\n",
      "--- Projects_Handled ---\n",
      "Lower Bound: -14.5\n",
      "Upper Bound: 45.5\n",
      "Outliers before: 1\n",
      "Outliers after: 0\n",
      "\n",
      "✅ Outlier treatment completed.\n",
      "\n",
      "✅ Data Integration complete.\n",
      "✅ Label Encoding done.\n",
      "✅ One-Hot Encoding done.\n",
      "✅ Scaling completed.\n",
      "✅ Log transformation done.\n",
      "✅ Discretization done.\n",
      "\n",
      "✅ PCA Completed Successfully!\n",
      "        PC1       PC2       PC3       PC4       PC5       PC6\n",
      "0 -1.821745 -0.405307 -0.921054  1.076279 -0.251508  0.014767\n",
      "1 -0.733096  1.559605 -0.551807 -1.615265 -0.007951 -1.098498\n",
      "2 -0.487664  0.005172 -0.669170 -0.859312  0.348112 -0.428727\n",
      "3  2.960330  1.693667  4.684910  0.656128  0.937243  0.306538\n",
      "4  0.833781 -1.241128 -0.767718  0.314779  0.009751  1.798871\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "df = pd.read_csv(\"employee_data.csv\")\n",
    "\n",
    "# ============================================================\n",
    "# ✅ STEP 1: DATA CLEANING\n",
    "# ============================================================\n",
    "\n",
    "# -------------------------\n",
    "# 1.1 HANDLE MISSING VALUES\n",
    "# -------------------------\n",
    "print(\"Missing values before cleaning:\\n\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Numeric columns imputation\n",
    "df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "df['Experience_Years'] = df['Experience_Years'].fillna(df['Experience_Years'].median())\n",
    "df['Salary_USD'] = df['Salary_USD'].fillna(df['Salary_USD'].mean())\n",
    "df['Bonus_%'] = df['Bonus_%'].fillna(df['Bonus_%'].median())\n",
    "df['Performance_Rating'] = df['Performance_Rating'].fillna(df['Performance_Rating'].mode()[0])\n",
    "df['Overtime_Hours_Monthly'] = df['Overtime_Hours_Monthly'].fillna(df['Overtime_Hours_Monthly'].median())\n",
    "df['Projects_Handled'] = df['Projects_Handled'].fillna(df['Projects_Handled'].mode()[0])\n",
    "\n",
    "# Categorical columns imputation\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "print(\"\\nMissing values after cleaning:\\n\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 1.2 FIX NOISY / INVALID VALUES\n",
    "# -------------------------\n",
    "\n",
    "# Age outside human range\n",
    "df.loc[(df['Age'] < 18) | (df['Age'] > 65), 'Age'] = np.random.randint(18, 66)\n",
    "\n",
    "# Experience outside possible range\n",
    "df.loc[(df['Experience_Years'] < 0) | (df['Experience_Years'] > 45), 'Experience_Years'] = \\\n",
    "    np.random.uniform(0, 45, size=df[(df['Experience_Years'] < 0) | (df['Experience_Years'] > 45)].shape[0])\n",
    "\n",
    "# Bonus exceeding typical corporate % range\n",
    "df.loc[df['Bonus_%'] > 50, 'Bonus_%'] = df['Bonus_%'].median()\n",
    "\n",
    "# Unrealistic overtime values\n",
    "df.loc[df['Overtime_Hours_Monthly'] > 100] = df['Overtime_Hours_Monthly'].median()\n",
    "\n",
    "# Fix invalid dates\n",
    "df['Joining_Date'] = pd.to_datetime(df['Joining_Date'], errors='coerce')\n",
    "df['Joining_Date'] = df['Joining_Date'].fillna(df['Joining_Date'].mode()[0])\n",
    "\n",
    "# Fix INR salaries accidentally mixed with USD\n",
    "median_salary = df['Salary_USD'].median()\n",
    "df.loc[df['Salary_USD'] > 20000, 'Salary_USD'] /= 80\n",
    "df.loc[df['Salary_USD'] <= 0, 'Salary_USD'] = median_salary\n",
    "\n",
    "print(\"\\n✅ Noisy values cleaned.\\n\")\n",
    "print(df.describe(include='all'))\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 1.3 REMOVE DUPLICATES\n",
    "# -------------------------\n",
    "print(\"\\nDuplicate rows before removal:\", df.duplicated().sum())\n",
    "df = df.drop_duplicates()\n",
    "print(\"Duplicate rows after removal:\", df.duplicated().sum())\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 1.4 OUTLIER HANDLING (IQR)\n",
    "# -------------------------\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "def treat_outliers_iqr(column):\n",
    "    Q1, Q3 = df[column].quantile([0.25, 0.75])\n",
    "    IQR = Q3 - Q1\n",
    "    lower, upper = Q1 - 1.5*IQR, Q3 + 1.5*IQR\n",
    "\n",
    "    print(f\"\\n--- {column} ---\")\n",
    "    print(\"Lower Bound:\", lower)\n",
    "    print(\"Upper Bound:\", upper)\n",
    "    print(\"Outliers before:\", ((df[column] < lower) | (df[column] > upper)).sum())\n",
    "\n",
    "    df[column] = np.clip(df[column], lower, upper)\n",
    "\n",
    "    print(\"Outliers after:\", ((df[column] < lower) | (df[column] > upper)).sum())\n",
    "\n",
    "for col in numeric_cols:\n",
    "    treat_outliers_iqr(col)\n",
    "\n",
    "print(\"\\n✅ Outlier treatment completed.\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ✅ STEP 2: DATA INTEGRATION\n",
    "# ============================================================\n",
    "\n",
    "# 2.1 Standardize column names (lowercase for consistency)\n",
    "df.columns = df.columns.str.lower()\n",
    "\n",
    "# 2.2 Fix remaining INR salaries (redundant check for safety)\n",
    "df.loc[df['salary_usd'] > 20000, 'salary_usd'] /= 80\n",
    "\n",
    "print(\"\\n✅ Data Integration complete.\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ✅ STEP 3: DATA TRANSFORMATION\n",
    "# ============================================================\n",
    "\n",
    "# -------------------------\n",
    "# 3.1 ENCODING\n",
    "# -------------------------\n",
    "\n",
    "# Label Encoding for binary or ordinal columns\n",
    "label_enc_cols = ['education_level', 'remote_work', 'attrition', 'gender']\n",
    "\n",
    "for col in label_enc_cols:\n",
    "    df[col] = df[col].astype(str)\n",
    "\n",
    "le = LabelEncoder()\n",
    "for col in label_enc_cols:\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "print(\"✅ Label Encoding done.\")\n",
    "\n",
    "# One-Hot Encoding for nominal categories\n",
    "one_hot_cols = ['department', 'job_role', 'city', 'state', 'country']\n",
    "df = pd.get_dummies(df, columns=one_hot_cols, drop_first=True)\n",
    "\n",
    "print(\"✅ One-Hot Encoding done.\")\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 3.2 SCALING (MinMax + Z-score)\n",
    "# -------------------------\n",
    "\n",
    "scaled_cols = ['age', 'experience_years', 'salary_usd', 'bonus_%',\n",
    "               'overtime_hours_monthly', 'projects_handled']\n",
    "\n",
    "# MinMax (0–1)\n",
    "mm = MinMaxScaler()\n",
    "df[scaled_cols] = mm.fit_transform(df[scaled_cols])\n",
    "\n",
    "# Standardization\n",
    "ss = StandardScaler()\n",
    "df[scaled_cols] = ss.fit_transform(df[scaled_cols])\n",
    "\n",
    "print(\"✅ Scaling completed.\")\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 3.3 LOG TRANSFORMATION on skewed features\n",
    "# (After scaling, ensure values > -1)\n",
    "# -------------------------\n",
    "\n",
    "log_cols = ['salary_usd', 'bonus_%']\n",
    "\n",
    "for col in log_cols:\n",
    "    # Ensure valid input for log1p\n",
    "    safe_values = np.where(df[col] > -1, df[col], -0.999999)\n",
    "    df[f'log_{col}'] = np.log1p(safe_values)\n",
    "\n",
    "print(\"✅ Log transformation done.\")\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 3.4 DISCRETIZATION (BINNING)\n",
    "# -------------------------\n",
    "\n",
    "df['salary_bin'] = pd.qcut(df['salary_usd'], q=3, labels=['Low', 'Medium', 'High'])\n",
    "\n",
    "print(\"✅ Discretization done.\")\n",
    "\n",
    "\n",
    "# Remove columns not useful for modeling\n",
    "columns_to_drop = ['name', 'joining_date']\n",
    "df = df.drop(columns=[c for c in columns_to_drop if c in df.columns], errors='ignore')\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ✅ STEP 4: DATA REDUCTION\n",
    "# ============================================================\n",
    "\n",
    "# -------------------------\n",
    "# 4.1 PCA on selected continuous features\n",
    "# -------------------------\n",
    "\n",
    "pca_cols = ['age', 'experience_years', 'salary_usd', 'bonus_%',\n",
    "            'overtime_hours_monthly', 'projects_handled']\n",
    "\n",
    "pca_input = df[pca_cols].fillna(df[pca_cols].mean())\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "pca_features = pca.fit_transform(pca_input)\n",
    "\n",
    "df_pca_final = pd.DataFrame(pca_features,\n",
    "                            columns=[f\"PC{i+1}\" for i in range(pca_features.shape[1])])\n",
    "\n",
    "print(\"\\n✅ PCA Completed Successfully!\")\n",
    "print(df_pca_final.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
